{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-21T14:37:58.739843Z","iopub.status.busy":"2022-12-21T14:37:58.739463Z","iopub.status.idle":"2022-12-21T14:38:25.693673Z","shell.execute_reply":"2022-12-21T14:38:25.692607Z","shell.execute_reply.started":"2022-12-21T14:37:58.739738Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-21 14:38:04.514863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:04.652392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:04.653401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:04.655203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-21 14:38:04.655570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:04.656582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:04.657553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:06.904768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:06.905685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:06.906513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-21 14:38:06.907265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["import tensorflow as tf \n","import numpy as np\n","import time\n","def get_f1(y_true, y_pred): \n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n","    return f1_val\n","pretrainedmodel_files = [\"/kaggle/input/modelaugmentat/model_segmentare_aug.h5\", \"/kaggle/input/clasificare-neaugmentat/model_neaugmentat_clasificare.h5\"]\n","A = tf.keras.models.load_model(\"/kaggle/input/modelaugmentat/model_segmentare_aug.h5\" , custom_objects={\"get_f1\": get_f1 })\n","B = tf.keras.models.load_model(\"/kaggle/input/clasificareaugmentat/model_augmentat_clasificare.h5\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-21T14:38:25.697144Z","iopub.status.busy":"2022-12-21T14:38:25.696412Z","iopub.status.idle":"2022-12-21T14:38:25.898079Z","shell.execute_reply":"2022-12-21T14:38:25.897007Z","shell.execute_reply.started":"2022-12-21T14:38:25.697103Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"finalModel\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n","_________________________________________________________________\n","model (Functional)           (None, 256, 256, 1)       31401345  \n","_________________________________________________________________\n","resizing (Resizing)          (None, 400, 400, 1)       0         \n","_________________________________________________________________\n","reshape (Reshape)            (None, 1, 400, 400)       0         \n","_________________________________________________________________\n","resizing_1 (Resizing)        (None, 3, 400, 400)       0         \n","_________________________________________________________________\n","permute (Permute)            (None, 400, 400, 3)       0         \n","_________________________________________________________________\n","sequential (Sequential)      (None, 3)                 75523107  \n","=================================================================\n","Total params: 106,924,452\n","Trainable params: 106,912,676\n","Non-trainable params: 11,776\n","_________________________________________________________________\n"]}],"source":["import tensorflow\n","from tensorflow.keras.layers.experimental.preprocessing import Resizing\n","from tensorflow.keras import Sequential\n","import keras\n","import keras.backend as K\n","from keras.layers import Concatenate, Reshape, Permute\n","\n","input_a = keras.Input(shape=(256,256,1))\n","input_b = keras.Input(shape=(400,400,3))\n","\n","masked_img = A(input_a)\n","masked_img = Resizing(400,400)(masked_img)\n","masked_img = Reshape((-1,400,400))(masked_img)\n","masked_img = Resizing(3,400)(masked_img)\n","masked_img = Permute((2,3,1))(masked_img)\n","second_img = B(masked_img)\n","\n","model_merged = tf.keras.Model(input_a, second_img, name=\"finalModel\")\n","\n","model_merged.summary()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-21T14:38:30.633051Z","iopub.status.busy":"2022-12-21T14:38:30.632234Z","iopub.status.idle":"2022-12-21T14:39:01.080819Z","shell.execute_reply":"2022-12-21T14:39:01.079841Z","shell.execute_reply.started":"2022-12-21T14:38:30.633014Z"},"trusted":true},"outputs":[],"source":["#train the model\n","import cv2\n","import tensorflow as tf\n","from glob import glob\n","import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from random import randint\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from PIL import Image\n","import os, shutil\n","\n","os.mkdir('/kaggle/working/images')\n","os.mkdir('/kaggle/working/images/benign')\n","os.mkdir('/kaggle/working/images/malignant')\n","os.mkdir('/kaggle/working/images/normal')\n","PATH = \"../input/augmented-data/BUSI - Augmented Dataset\"\n","directory = os.path.join(PATH,\"benign/\")\n","for filename in os.listdir(directory):\n","    if \"mask\" not in filename: \n","         shutil.copy2(os.path.join(PATH,f\"benign/{filename}\"), f\"/kaggle/working/images/benign/{filename}\")\n","\n","directory = os.path.join(PATH,\"malignant/\")\n","for filename in os.listdir(directory):\n","    if \"mask\" not in filename: \n","         shutil.copy2(os.path.join(PATH,f\"malignant/{filename}\"), f\"/kaggle/working/images/malignant/{filename}\")\n","\n","directory = os.path.join(PATH,\"normal/\")\n","for filename in os.listdir(directory):\n","    if \"mask\" not in filename: \n","         shutil.copy2(os.path.join(PATH,f\"normal/{filename}\"), f\"/kaggle/working/images/normal/{filename}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import tensorflow as tf\n","from glob import glob\n","import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from random import randint\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from PIL import Image\n","import os, shutil\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n","session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n","batch_size = 16\n","epochs = 32\n","steps_train = 18\n","steps_val = 3\n","img_height = 256\n","img_width = 256\n","data_dir='/kaggle/working/images/'\n","model_merged.compile(loss='categorical_crossentropy',\n","optimizer=\"adam\",\n","metrics=['acc'])\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","data_dir,\n","validation_split=0.25,\n","subset=\"training\",\n","seed=123,\n","image_size=(img_height, img_width),\n","label_mode=\"categorical\",\n","batch_size=batch_size)\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","data_dir,\n","validation_split=0.25,\n","subset=\"validation\",\n","seed=123,\n","image_size=(img_height, img_width),\n","label_mode=\"categorical\",\n","batch_size=batch_size)\n","\n","# scale pixel value between 0 and 1\n","normalization_layer = tf.keras.layers.Rescaling(1./255)\n","reshape_layer = Reshape((-1,256,256))\n","resize_layer = Resizing(1,256)\n","permute_layer = Permute((2,3,1))\n","\n","train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n","val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n","train_ds = train_ds.map(lambda x, y: (reshape_layer(x), y))\n","val_ds = val_ds.map(lambda x, y: (reshape_layer(x), y))\n","train_ds = train_ds.map(lambda x, y: (resize_layer(x), y))\n","val_ds = val_ds.map(lambda x, y: (resize_layer(x), y))\n","train_ds = train_ds.map(lambda x, y: (permute_layer(x), y))\n","val_ds = val_ds.map(lambda x, y: (permute_layer(x), y))\n","\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","history = model_merged.fit(\n","train_ds,\n","steps_per_epoch=steps_train,\n","epochs=epochs,\n","validation_data = val_ds,\n","validation_steps = steps_val,\n","verbose=1)\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.show()"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T20:47:02.276669Z","iopub.status.busy":"2022-12-19T20:47:02.276306Z","iopub.status.idle":"2022-12-19T20:47:02.285865Z","shell.execute_reply":"2022-12-19T20:47:02.284863Z","shell.execute_reply.started":"2022-12-19T20:47:02.276639Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Accuracy:\n","0.9947916865348816\n","Testing Accuracy:\n","0.71875\n"]},{"data":{"text/plain":["(None, None)"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["print(\"Training Accuracy:\"), print(history.history['acc'][-1])\n","print(\"Testing Accuracy:\"), print (history.history['val_acc'][-1])"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T18:53:51.692258Z","iopub.status.busy":"2022-12-19T18:53:51.691816Z","iopub.status.idle":"2022-12-19T18:54:09.751078Z","shell.execute_reply":"2022-12-19T18:54:09.750074Z","shell.execute_reply.started":"2022-12-19T18:53:51.692225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.7141962051391602\n"]}],"source":["# Compute inference time for segmentation\n","import cv2\n","import tensorflow as tf\n","from glob import glob\n","import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from random import randint\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from PIL import Image\n","import time\n","\n","\n","PATH = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\"\n","def process_image(image, HEIGHT=256, WIDTH=256):\n","    image = image.decode(\"utf-8\")\n","    image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n","    image = cv2.resize(image, (HEIGHT, WIDTH))\n","    image = image / 255.0\n","\n","    image = image.astype(np.float32)\n","    image = np.expand_dims(image, axis=-1)\n","    return image\n","def process_mask(mask):\n","    mask = mask.astype(np.float32)\n","    mask = mask / 255\n","    mask = np.round(mask) \n","    mask = np.expand_dims(mask, axis=-1) \n","    return mask\n","\n","def preprocess(x, y):\n","    def f(x, y):\n","        image = process_image(x)\n","        mask = process_mask(y)\n","        return image, mask\n","\n","    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n","    image.set_shape([256, 256, 1])\n","    mask.set_shape([256, 256, 1])\n","    return image, mask\n","# combine real masks where there are more masks for the same image\n","def group_masks(masks):\n","    new_masks = []\n","    index = 0\n","    for i in range(len(masks)):\n","        m = re.search(r\"mask_[0-9]\", masks[i]) # we are looking for masks that correspond to the same inputs\n","        if m:\n","            new_masks[i - (index + 1)] += cv2.resize(\n","                cv2.imread(masks[i], cv2.IMREAD_GRAYSCALE), (256, 256)\n","            )\n","            index += 1\n","        else:\n","            new_masks.append(\n","                cv2.resize(\n","                    cv2.imread(masks[i], cv2.IMREAD_GRAYSCALE), (256, 256)\n","                )  \n","            )\n","\n","    return new_masks\n","benign_images = sorted(\n","        glob(os.path.join(PATH,\"benign/*).png\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    )\n","benign_masks = group_masks(sorted(\n","        glob(os.path.join(PATH, \"benign/*mask*\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    ))\n","malignant_images = sorted(\n","        glob(os.path.join(PATH,\"malignant/*).png\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    )\n","malignant_masks = group_masks(sorted(\n","        glob(os.path.join(PATH, \"malignant/*mask*\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    ))\n","normal_images = sorted(\n","        glob(os.path.join(PATH,\"normal/*).png\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    )\n","normal_masks = group_masks(sorted(\n","        glob(os.path.join(PATH, \"normal/*mask*\")),\n","        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r\"(\\d+)\", x)],\n","    ))\n","# Version 1: we just train on benign and malignant masks\n","all_images = benign_images + malignant_images\n","all_masks = benign_masks + malignant_masks\n","X_train, X_test = train_test_split(\n","        all_images,\n","        test_size=0.2,\n","        random_state=1,\n","        shuffle=True\n","    )\n","y_train, y_test = train_test_split(\n","    all_masks,\n","    test_size=0.2,\n","    random_state=1,\n","    shuffle=True\n",")\n","batch_size = 16\n","train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","train_ds = train_ds.map(preprocess)\n","train_ds = train_ds.batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n","test_ds = test_ds.map(preprocess)\n","test_ds = test_ds.batch(batch_size)\n","\n","all_ds = train_ds.concatenate(test_ds)\n","original_images = list(all_ds.map(lambda x, y: y*255))\n","images_to_mask = list(all_ds.map(lambda x, y: x*255))\n","start = time.time()\n","for i in range(10):\n","    pred = A.predict(images_to_mask[i])\n","end = time.time()\n","print(end - start)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-12-19T19:26:40.036327Z","iopub.status.busy":"2022-12-19T19:26:40.035650Z","iopub.status.idle":"2022-12-19T19:26:40.496264Z","shell.execute_reply":"2022-12-19T19:26:40.495216Z","shell.execute_reply.started":"2022-12-19T19:26:40.036291Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 45 images belonging to 3 classes.\n","0.3506283760070801\n"]}],"source":["from keras.preprocessing.image import ImageDataGenerator\n","# inference time for classification\n","predict_datagen =ImageDataGenerator(rescale=1./255)\n","predict_generator = predict_datagen.flow_from_directory(\n","    '/kaggle/input/sample-dataset-masti-neaugmentate',  # Source directory\n","    target_size=(400, 400),  # Resizes images\n","    batch_size=15,\n","    class_mode='categorical')\n","\n","start = time.time()\n","B.predict_generator(\n","  predict_generator,\n","  steps=3,\n","  max_queue_size = 15,\n","  workers = 1,\n","  verbose = 0\n",")\n","end = time.time()\n","print(end - start)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
